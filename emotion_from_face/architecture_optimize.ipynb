{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3b7e01e-e549-486d-9122-c568a4a66738",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02de903f-a0ee-40c0-89c4-55887c289154",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-25 08:37:32.653857: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-09-25 08:37:32.685332: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7809eff4-91da-4cc0-8b0c-dd091e415243",
   "metadata": {},
   "outputs": [],
   "source": [
    "import node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07ee0a91-c823-47c5-9d65-623a1dda5037",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbc70f8f-9b56-46c4-bce8-134be4994cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd149351-79d8-4b60-a00a-4b1fa5cf2fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f0a70ea1-2d16-4c7b-9d9b-d28e78042ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    import pandas\n",
    "    pandas.read_csv(constant.train_data_csv_file_path)\n",
    "    # pandas.read_csv(constant.train_data_csv_file_path)\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fcd30bfc-ecaa-4a29-b619-cc994209ceae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "def keras_inputs_and_labels_from_data_frame(a_data_frame, input_column_name='image',label_column_name='emotion'):\n",
    "    get_all_inputs_as_array_from_matrix_series = lambda matrix_series: numpy.stack([ matrix for matrix in matrix_series ])\n",
    "    train_inputs_as_array = get_all_inputs_as_array_from_matrix_series(train_data_frame[input_column_name])\n",
    "    train_labels_as_one_hot_encoded = keras.utils.to_categorical(train_data_frame[label_column_name].to_numpy())\n",
    "    return train_inputs_as_array, train_labels_as_one_hot_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4000711f-2012-4808-a76c-00df4008c288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_inputs_as_array_and_train_labels_as_one_hot_encoded = keras.utils.image_dataset_from_directory(\n",
    "#     directory='../data_png/train/',\n",
    "#     labels='inferred',\n",
    "#     label_mode='categorical',\n",
    "#     color_mode='grayscale',\n",
    "#     batch_size=32,\n",
    "#     image_size=(48,48),\n",
    "# )\n",
    "# # dataset genreator of (32*input, 32*label)\n",
    "# # train_labels_as_one_hot_encoded = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d60714ff-03b7-4869-9400-23cb8bf3dcdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_frame = fer.get_data_from_path(\n",
    "    data_path=constant.train_data_csv_file_path,\n",
    "    # data_path='../data_csv/train/data.csv',\n",
    "    input_image_format='numerals',\n",
    "    output_image_format='matrix',\n",
    "    sampling_quantity=None,\n",
    ")\n",
    "train_inputs_as_array, train_labels_as_one_hot_encoded = keras_inputs_and_labels_from_data_frame( train_data_frame )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f633c767-2973-4461-a4b4-22a2f4ad60b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# validate_inputs_as_array_and_validate_labels_as_one_hot_encoded = keras.utils.image_dataset_from_directory(\n",
    "#     directory='../data_png/validate/',\n",
    "#     labels='inferred',\n",
    "#     label_mode='categorical',\n",
    "#     color_mode='grayscale',\n",
    "#     batch_size=32,\n",
    "#     image_size=(48,48),\n",
    "# )\n",
    "# # dataset genreator of (32*input, 32*label)\n",
    "# validate_labels_as_one_hot_encoded = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b212fe47-52df-4719-9fe7-3209c54c6a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_data_frame = fer.get_data_from_path(\n",
    "    data_path=constant.validate_data_csv_file_path,\n",
    "    input_image_format='numerals',\n",
    "    output_image_format='matrix',\n",
    "    sampling_quantity=None,\n",
    ")\n",
    "vallidate_inputs_as_array, vallidate_labels_as_one_hot_encoded = keras_inputs_and_labels_from_data_frame( vallidate_data_frame )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5e6aacd0-8b64-4a3f-9fbb-18741b8aed2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_data_graph_from_data_nodes(datas):\n",
    "    first_data_node = node.DataNode(data=datas[0] ,parents=None)\n",
    "    last_data_node = first_data_node\n",
    "    for data in datas[1:-1]:\n",
    "        last_data_node = node.DataNode(data=data).add_parent(last_data_node)\n",
    "    last_data_node = node.DataNode(data=datas[-1], children=None).add_parent(last_data_node)\n",
    "    return first_data_node, last_data_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "37dee972-d059-41bb-8df8-7cb0387d9e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scores_from_path_data_graph(\n",
    "    last_data_node,\n",
    "    input_shape,\n",
    "    first_data_node,\n",
    "    train_inputs_as_array,\n",
    "    train_labels_as_one_hot_encoded,\n",
    "    validate_inputs_as_array,\n",
    "    validate_labels_as_one_hot_encoded,\n",
    "    epochs=10,\n",
    "    callbacks=[\n",
    "        keras.callbacks.EarlyStopping(patience=3, restore_best_weights=False, monitor='accuracy', min_delta=0.005, verbose=1),\n",
    "        keras.callbacks.EarlyStopping(patience=4, restore_best_weights=False, monitor='val_accuracy', min_delta=0.005, verbose=1),\n",
    "    ],\n",
    "    verbose=1,\n",
    "    batch_size=16\n",
    "):\n",
    "    \n",
    "    assert input_shape == train_inputs_as_array.shape[1:] == validate_inputs_as_array.shape[1:], f\"{input_shape = } {train_inputs_as_array.shape[1:] = } {validate_inputs_as_array.shape[1:] = }\"\n",
    "    keras_model = node.path_keras_model_from_last_data_node(\n",
    "        last_data_node=last_data_node, \n",
    "        input_shape=input_shape,\n",
    "        first_data_node=first_data_node,\n",
    "    )\n",
    "    keras_model.compile(\n",
    "        optimizer='adam', \n",
    "        loss='categorical_crossentropy', \n",
    "        metrics=['accuracy'],\n",
    "    )\n",
    "    keras_model.summary()\n",
    "    # print(f\"{[train_inputs_as_array[0]] = }\")\n",
    "    # print(f\"{train_inputs_as_array[0].shape = }\")\n",
    "    # print(f\"{keras_model.predict( [ numpy.expand_dims(train_inputs_as_array[0], axis=0) ] ) = }\")\n",
    "    assert (batch_size & (batch_size-1) == 0) and batch_size != 0 ,f\"internet says that batch size: {batch_size} should be a power of two\"\n",
    "    assert train_inputs_as_array.shape == ( *train_labels_as_one_hot_encoded.shape[:1] , *input_shape ), f\"shape missmatch\"\n",
    "    history = keras_model.fit(\n",
    "        x=train_inputs_as_array,\n",
    "        y=train_labels_as_one_hot_encoded,\n",
    "        validation_data=(validate_inputs_as_array,validate_labels_as_one_hot_encoded),\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_batch_size=batch_size,\n",
    "        callbacks=callbacks,\n",
    "        verbose=verbose,\n",
    "    )\n",
    "    score_by_metric = { metric: values[-1] for metric, values in history.history.items() }\n",
    "    return score_by_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b05b7f-45a6-42b0-9b16-32d62fd20b61",
   "metadata": {},
   "source": [
    "starting from the reference/control DCNN, \n",
    "keeping in mind we need to achieve 60% accuracy (test),\n",
    "- DCNN reference\n",
    "    - ~ 0.57 validation accuracy before 10 epochs\n",
    "from little experiment we can assume that:\n",
    "- we can easily:\n",
    "    - add augmentation layer (rotation, shift, flip)\n",
    "        - ~ 0.55 validation accurary before 10 epochs expect horizontal flip which reduce a little bit accuracy\n",
    "    - reduced convolution kernel size\n",
    "        - ~ 0.55 validation accurary before 10 epochs\n",
    "    - reduced convolution features number\n",
    "        - ~ 0.55 | 0.57 validation accurary before 10 epochs\n",
    "- at the cost of some overfitting:\n",
    "    - remove dropout layers\n",
    "        - ~ 0.55 validation accurary before 10 epochs\n",
    "- reduce validation accuracy and training time\n",
    "    - half the number of training inputs\n",
    "        - ~ 0.50 before 10 epochs\n",
    "- did not work at all:\n",
    "    - adding layer normalization\n",
    "    - removing just batch normalization\n",
    "    - batch size below 64 perform same\n",
    "\n",
    "so we will genreate random convolution starting from reference.\n",
    "    mutations will be about:\n",
    "        - mutation convolution kernel size\n",
    "        - mutating comvolution features number\n",
    "        - mutating dropout ratio\n",
    "    to speed up thing we will cut the number of input by half but add augmentation layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "71f5fff0-a643-4972-8a4d-1318d11dbb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def mutated_dcnn_datas(dcnn_datas, number_of_mutations=1):\n",
    "    def is_mutable_data(a_data):\n",
    "        return hasattr(a_data, 'mutated')\n",
    "\n",
    "    def get_indices_of_mutables_datas(datas):\n",
    "        return list(\n",
    "            index\n",
    "            for index, data in enumerate(datas)\n",
    "            if is_mutable_data(data)\n",
    "        )\n",
    "    assert get_indices_of_mutables_datas(dcnn_datas), f\"no mutable data ? {dcnn_datas}\"\n",
    "    indices_of_data_to_mutate = random.sample(get_indices_of_mutables_datas(dcnn_datas), number_of_mutations)\n",
    "    return list(\n",
    "        data.mutated() if index in indices_of_data_to_mutate else data\n",
    "        for index, data in enumerate(dcnn_datas)\n",
    "    )\n",
    "\n",
    "def expanded_dcnn_datas(\n",
    "    dcnn_datas, \n",
    "    pool_of_layers=[\n",
    "        data.MaxPoolingData, data.DropoutData, \n",
    "        data.BatchNormalizationData, data.LayerNormalizationData,\n",
    "        lambda : data.ConvolutionData(features=512,shape=(3,3)), # we do not want to bottleneck dimensionality\n",
    "    ],\n",
    "):\n",
    "    flatten_layer_index = None\n",
    "    for index, a_data in enumerate(dcnn_datas):\n",
    "        if isinstance(a_data, data.FlattenData):\n",
    "            flatten_layer_index = index\n",
    "            break\n",
    "    flatten_layer_index = len(dcnn_datas)-1 if not flatten_layer_index else flatten_layer_index\n",
    "    \n",
    "    intercalation_index = random.randrange(flatten_layer_index)\n",
    "    return dcnn_datas[:intercalation_index] + [random.choice(pool_of_layers)()] + dcnn_datas[intercalation_index:]\n",
    "\n",
    "def shrank_dcnn_datas(\n",
    "    dcnn_datas, \n",
    "):\n",
    "    flatten_layer_index = None\n",
    "    for index, a_data in enumerate(dcnn_datas):\n",
    "        if isinstance(a_data, data.FlattenData):\n",
    "            flatten_layer_index = index\n",
    "            break\n",
    "    flatten_layer_index = len(dcnn_datas) if not flatten_layer_index else flatten_layer_index\n",
    "    removing_index = random.randrange(flatten_layer_index)\n",
    "    return dcnn_datas[:removing_index] + dcnn_datas[removing_index+1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "125f98ad-6ddc-4a88-a941-fa81e0d30e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "class TimeOut(keras.callbacks.Callback):\n",
    "    def __init__(self, t0, timeout):\n",
    "        super().__init__()\n",
    "        self.t0 = t0\n",
    "        self.timeout = timeout  # time in minutes\n",
    "\n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        if time.time() - self.t0 > self.timeout * 60:  # 58 minutes\n",
    "            print(f\"\\nReached {(time.time() - self.t0) / 60:.3f} minutes of training, stopping\")\n",
    "            self.model.stop_training = True\n",
    "\n",
    "callbacks = [TimeOut(t0=time.time(), timeout=58)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "62db52ca-ffaf-4896-8be4-57aae5d3677a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os \n",
    "import constant\n",
    "def save_datas_as_pickle(the_datas, destination_folder_path=constant.architecture_folder_path, file_name=None):\n",
    "    file_name = f\"architecture_data_{random.randint(1,999)}\"\n",
    "    if not os.path.exists(destination_folder_path):\n",
    "        os.makedirs(destination_folder_path)\n",
    "    destination_file_path = f\"{destination_folder_path}{file_name}\"\n",
    "    with open(destination_file_path, 'wb') as handle:\n",
    "        pickle.dump(the_datas, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    with open(destination_file_path, 'rb') as handle:\n",
    "        loaded_datas = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5fdc473c-a20b-41c7-b5c2-d4c5a7bcd415",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evolve_datas(\n",
    "    train_inputs_as_array,\n",
    "    train_labels_as_one_hot_encoded,\n",
    "    validate_inputs_as_array,\n",
    "    validate_labels_as_one_hot_encoded,\n",
    "    initial_dcnn_datas,\n",
    "    augmentation_datas,\n",
    "    preprocessing_datas,\n",
    "    validation_accuracy=None,\n",
    "):\n",
    "    for _ in range(20):\n",
    "        better_datas, better_validation_accuracy = one_datas_evolution_cycle(\n",
    "            train_inputs_as_array=train_inputs_as_array,\n",
    "            train_labels_as_one_hot_encoded=train_labels_as_one_hot_encoded,\n",
    "            validate_inputs_as_array=validate_inputs_as_array,\n",
    "            validate_labels_as_one_hot_encoded=validate_labels_as_one_hot_encoded,\n",
    "            initial_dcnn_datas=initial_dcnn_datas,\n",
    "            augmentation_datas=augmentation_datas,\n",
    "            preprocessing_datas=preprocessing_datas,\n",
    "            validation_accuracy=validation_accuracy,\n",
    "        )\n",
    "        if better_validation_accuracy:\n",
    "            saved_datas_file_path = f\"{constant.architecture_folder_path}dcnn_validatation_accuracy_{int(better_validation_accuracy*100)}\"\n",
    "            save_datas_as_pickle(\n",
    "                better_datas, \n",
    "                constant.architecture_folder_path, \n",
    "                saved_datas_file_path,\n",
    "            )\n",
    "    return saved_datas_file_path\n",
    "\n",
    "def one_datas_evolution_cycle(\n",
    "    train_inputs_as_array,\n",
    "    train_labels_as_one_hot_encoded,\n",
    "    validate_inputs_as_array,\n",
    "    validate_labels_as_one_hot_encoded,\n",
    "    initial_dcnn_datas,\n",
    "    augmentation_datas,\n",
    "    preprocessing_datas,\n",
    "    validation_accuracy=None,\n",
    "):\n",
    "    retained_dcnn_datas = initial_dcnn_datas\n",
    "\n",
    "    def validation_accuracy_from_dcnn_datas(dcnn_datas):\n",
    "        pipeline_path_data_graph = path_data_graph_from_data_nodes( augmentation_datas + preprocessing_datas + dcnn_datas )\n",
    "        return scores_from_path_data_graph(\n",
    "            last_data_node=pipeline_path_data_graph[-1],\n",
    "            input_shape=(48,48),\n",
    "            first_data_node=pipeline_path_data_graph[0],\n",
    "            train_inputs_as_array=train_inputs_as_array,\n",
    "            train_labels_as_one_hot_encoded=train_labels_as_one_hot_encoded,\n",
    "            validate_inputs_as_array=validate_inputs_as_array,\n",
    "            validate_labels_as_one_hot_encoded=validate_labels_as_one_hot_encoded,\n",
    "            epochs=40,\n",
    "            callbacks=[\n",
    "                keras.callbacks.EarlyStopping(patience=3, restore_best_weights=False, monitor='accuracy', min_delta=0.005, verbose=1),\n",
    "                keras.callbacks.EarlyStopping(patience=4, restore_best_weights=False, monitor='val_accuracy', min_delta=0.005, verbose=1),\n",
    "                TimeOut(t0=time.time(), timeout=2),\n",
    "            ],\n",
    "            verbose=1,\n",
    "            batch_size=32,\n",
    "        )['val_accuracy']\n",
    "\n",
    "    if not validation_accuracy:\n",
    "        validation_accuracy = validation_accuracy_from_dcnn_datas(dcnn_datas=initial_dcnn_datas)    \n",
    "    # validation_accuracy = 0.1    \n",
    "    # while True:\n",
    "    saved_datas_file_path = None\n",
    "    new_created_dcnn_datas = random.choice([mutated_dcnn_datas, expanded_dcnn_datas, shrank_dcnn_datas])\n",
    "    print(f\"try one evolution step {new_created_dcnn_datas = }\")\n",
    "    try:\n",
    "        new_dcnn_datas = new_created_dcnn_datas(retained_dcnn_datas)\n",
    "        new_validation_accuracy = validation_accuracy_from_dcnn_datas(new_dcnn_datas)\n",
    "    except Exception as e:\n",
    "        print(f\"failed during mutation: {e}\")\n",
    "        print(f\"{new_dcnn_datas = }\")\n",
    "    if new_validation_accuracy > validation_accuracy:\n",
    "        print(f\"\\n new best val accuracy:{new_validation_accuracy = }\")\n",
    "        print(f\"new best model:{new_dcnn_datas}\")\n",
    "        return new_dcnn_datas, new_validation_accuracy\n",
    "    else:\n",
    "        print(\"new model is not better\")\n",
    "    return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "73d49833-c32a-43c9-a7f6-fdddb6daec1d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ random_rotation_1               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RandomRotation</span>)                │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ random_translation_1            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RandomTranslation</span>)             │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ random_flip_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RandomFlip</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">44</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">44</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">832</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_13          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">44</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">44</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">25,632</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_12          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_11          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_10          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_9           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_8           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">65,664</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_7           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">903</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m48\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ random_rotation_1               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m48\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mRandomRotation\u001b[0m)                │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ random_translation_1            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m48\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mRandomTranslation\u001b[0m)             │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ random_flip_1 (\u001b[38;5;33mRandomFlip\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m48\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape_1 (\u001b[38;5;33mReshape\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_11 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m44\u001b[0m, \u001b[38;5;34m44\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m832\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_13          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m44\u001b[0m, \u001b[38;5;34m44\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_10 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │        \u001b[38;5;34m25,632\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_12          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_5 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_11          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m36,928\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_10          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_4 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_9           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │       \u001b[38;5;34m147,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_8           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m65,664\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_7           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │           \u001b[38;5;34m903\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">372,199</span> (1.42 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m372,199\u001b[0m (1.42 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">371,047</span> (1.42 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m371,047\u001b[0m (1.42 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,152</span> (4.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,152\u001b[0m (4.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "\u001b[1m 50/898\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:09\u001b[0m 82ms/step - accuracy: 0.1226 - loss: 3.3905"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 65\u001b[0m\n\u001b[1;32m     54\u001b[0m     validate_inputs_as_array, validate_labels_as_one_hot_encoded \u001b[38;5;241m=\u001b[39m keras_inputs_and_labels_from_data_frame(validate_data_frame)\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m evolve_datas(\n\u001b[1;32m     56\u001b[0m         train_inputs_as_array\u001b[38;5;241m=\u001b[39mtrain_inputs_as_array,\n\u001b[1;32m     57\u001b[0m         train_labels_as_one_hot_encoded\u001b[38;5;241m=\u001b[39mtrain_labels_as_one_hot_encoded,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[38;5;66;03m# retained_validation_accuracies=retained_validation_accuracies,\u001b[39;00m\n\u001b[1;32m     64\u001b[0m     )\n\u001b[0;32m---> 65\u001b[0m saved_datas_path \u001b[38;5;241m=\u001b[39m \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[38], line 55\u001b[0m, in \u001b[0;36mtest\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m train_inputs_as_array, train_labels_as_one_hot_encoded \u001b[38;5;241m=\u001b[39m keras_inputs_and_labels_from_data_frame(sampled_train_data_frame)\n\u001b[1;32m     54\u001b[0m validate_inputs_as_array, validate_labels_as_one_hot_encoded \u001b[38;5;241m=\u001b[39m keras_inputs_and_labels_from_data_frame(validate_data_frame)\n\u001b[0;32m---> 55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mevolve_datas\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_inputs_as_array\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_inputs_as_array\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_labels_as_one_hot_encoded\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_labels_as_one_hot_encoded\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidate_inputs_as_array\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_inputs_as_array\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidate_labels_as_one_hot_encoded\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_labels_as_one_hot_encoded\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_dcnn_datas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdcnn_datas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m    \u001b[49m\u001b[43maugmentation_datas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maugmentation_datas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreprocessing_datas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreprocessing_datas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# retained_validation_accuracies=retained_validation_accuracies,\u001b[39;49;00m\n\u001b[1;32m     64\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[37], line 12\u001b[0m, in \u001b[0;36mevolve_datas\u001b[0;34m(train_inputs_as_array, train_labels_as_one_hot_encoded, validate_inputs_as_array, validate_labels_as_one_hot_encoded, initial_dcnn_datas, augmentation_datas, preprocessing_datas, validation_accuracy)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevolve_datas\u001b[39m(\n\u001b[1;32m      2\u001b[0m     train_inputs_as_array,\n\u001b[1;32m      3\u001b[0m     train_labels_as_one_hot_encoded,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m     validation_accuracy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     10\u001b[0m ):\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m20\u001b[39m):\n\u001b[0;32m---> 12\u001b[0m         better_datas, better_validation_accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mone_datas_evolution_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtrain_inputs_as_array\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_inputs_as_array\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtrain_labels_as_one_hot_encoded\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_labels_as_one_hot_encoded\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalidate_inputs_as_array\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_inputs_as_array\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalidate_labels_as_one_hot_encoded\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_labels_as_one_hot_encoded\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m            \u001b[49m\u001b[43minitial_dcnn_datas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_dcnn_datas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m            \u001b[49m\u001b[43maugmentation_datas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maugmentation_datas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpreprocessing_datas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreprocessing_datas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalidation_accuracy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_accuracy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m better_validation_accuracy:\n\u001b[1;32m     23\u001b[0m             saved_datas_file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconstant\u001b[38;5;241m.\u001b[39marchitecture_folder_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mdcnn_validatation_accuracy_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mint\u001b[39m(better_validation_accuracy\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "Cell \u001b[0;32mIn[37], line 64\u001b[0m, in \u001b[0;36mone_datas_evolution_step\u001b[0;34m(train_inputs_as_array, train_labels_as_one_hot_encoded, validate_inputs_as_array, validate_labels_as_one_hot_encoded, initial_dcnn_datas, augmentation_datas, preprocessing_datas, validation_accuracy)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m scores_from_path_data_graph(\n\u001b[1;32m     46\u001b[0m         last_data_node\u001b[38;5;241m=\u001b[39mpipeline_path_data_graph[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m     47\u001b[0m         input_shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m48\u001b[39m,\u001b[38;5;241m48\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     60\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m,\n\u001b[1;32m     61\u001b[0m     )[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validation_accuracy:\n\u001b[0;32m---> 64\u001b[0m     validation_accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mvalidation_accuracy_from_dcnn_datas\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdcnn_datas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_dcnn_datas\u001b[49m\u001b[43m)\u001b[49m    \n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# validation_accuracy = 0.1    \u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m# while True:\u001b[39;00m\n\u001b[1;32m     67\u001b[0m saved_datas_file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[37], line 45\u001b[0m, in \u001b[0;36mone_datas_evolution_step.<locals>.validation_accuracy_from_dcnn_datas\u001b[0;34m(dcnn_datas)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalidation_accuracy_from_dcnn_datas\u001b[39m(dcnn_datas):\n\u001b[1;32m     44\u001b[0m     pipeline_path_data_graph \u001b[38;5;241m=\u001b[39m path_data_graph_from_data_nodes( augmentation_datas \u001b[38;5;241m+\u001b[39m preprocessing_datas \u001b[38;5;241m+\u001b[39m dcnn_datas )\n\u001b[0;32m---> 45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mscores_from_path_data_graph\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlast_data_node\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpipeline_path_data_graph\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m48\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m48\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfirst_data_node\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpipeline_path_data_graph\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_inputs_as_array\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_inputs_as_array\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_labels_as_one_hot_encoded\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_labels_as_one_hot_encoded\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate_inputs_as_array\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_inputs_as_array\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate_labels_as_one_hot_encoded\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_labels_as_one_hot_encoded\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m40\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m            \u001b[49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEarlyStopping\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrestore_best_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmonitor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maccuracy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_delta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.005\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m            \u001b[49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEarlyStopping\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrestore_best_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmonitor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mval_accuracy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_delta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.005\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m            \u001b[49m\u001b[43mTimeOut\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtime\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "Cell \u001b[0;32mIn[33], line 35\u001b[0m, in \u001b[0;36mscores_from_path_data_graph\u001b[0;34m(last_data_node, input_shape, first_data_node, train_inputs_as_array, train_labels_as_one_hot_encoded, validate_inputs_as_array, validate_labels_as_one_hot_encoded, epochs, callbacks, verbose, batch_size)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (batch_size \u001b[38;5;241m&\u001b[39m (batch_size\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m batch_size \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m ,\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minternet says that batch size: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m should be a power of two\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m train_inputs_as_array\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m ( \u001b[38;5;241m*\u001b[39mtrain_labels_as_one_hot_encoded\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m1\u001b[39m] , \u001b[38;5;241m*\u001b[39minput_shape ), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape missmatch\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 35\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mkeras_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_inputs_as_array\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_labels_as_one_hot_encoded\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvalidate_inputs_as_array\u001b[49m\u001b[43m,\u001b[49m\u001b[43mvalidate_labels_as_one_hot_encoded\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m score_by_metric \u001b[38;5;241m=\u001b[39m { metric: values[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m metric, values \u001b[38;5;129;01min\u001b[39;00m history\u001b[38;5;241m.\u001b[39mhistory\u001b[38;5;241m.\u001b[39mitems() }\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m score_by_metric\n",
      "File \u001b[0;32m~/kood/emotions-detector/emotion_recognition/envs/emotion_recognition/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/kood/emotions-detector/emotion_recognition/envs/emotion_recognition/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:320\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[1;32m    319\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 320\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[1;32m    322\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n",
      "File \u001b[0;32m~/kood/emotions-detector/emotion_recognition/envs/emotion_recognition/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/kood/emotions-detector/emotion_recognition/envs/emotion_recognition/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/kood/emotions-detector/emotion_recognition/envs/emotion_recognition/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/kood/emotions-detector/emotion_recognition/envs/emotion_recognition/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/kood/emotions-detector/emotion_recognition/envs/emotion_recognition/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/kood/emotions-detector/emotion_recognition/envs/emotion_recognition/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/kood/emotions-detector/emotion_recognition/envs/emotion_recognition/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/kood/emotions-detector/emotion_recognition/envs/emotion_recognition/lib/python3.12/site-packages/tensorflow/python/eager/context.py:1552\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1550\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1552\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1553\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1554\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1555\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1556\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1557\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1558\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1560\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1561\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1562\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1566\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1567\u001b[0m   )\n",
      "File \u001b[0;32m~/kood/emotions-detector/emotion_recognition/envs/emotion_recognition/lib/python3.12/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def test():\n",
    "\n",
    "    sampled_train_data_frame = fer.sampled_data_frame(\n",
    "        train_data_frame,\n",
    "        to_be_preserved_column_names=['emotion'],\n",
    "        sampling_quantity=3000,\n",
    "    )\n",
    "    # print(f\"{sampled_train_data_frame.info() = }\")\n",
    "\n",
    "    augmentation_datas = [\n",
    "        data.data_from_keras_layer( keras.layers.RandomRotation, factor=0.005 ),\n",
    "        data.data_from_keras_layer( keras.layers.RandomTranslation, height_factor=0.01, width_factor=0.01 ),\n",
    "        data.data_from_keras_layer( keras.layers.RandomFlip, mode='horizontal' ),\n",
    "    ]\n",
    "\n",
    "    preprocessing_datas = [\n",
    "        data.data_from_keras_layer( keras.layers.Reshape, target_shape=(48, 48, 1) ),\n",
    "    ]\n",
    "\n",
    "    dcnn_datas = [ # reduced features\n",
    "        data.ConvolutionData(shape=(5,5),features=32,activation='elu'),data.BatchNormalizationData(),\n",
    "        data.ConvolutionData(shape=(5,5),features=32,activation='elu'),data.BatchNormalizationData(),\n",
    "        data.MaxPoolingData(shape=(2,2)), data.DropoutData(rate=0.4),\n",
    "        data.ConvolutionData(shape=(3,3),features=64,activation='elu'),data.BatchNormalizationData(),\n",
    "        data.ConvolutionData(shape=(3,3),features=64,activation='elu'),data.BatchNormalizationData(),\n",
    "        data.MaxPoolingData(shape=(2,2)), data.DropoutData(rate=0.4),\n",
    "        data.ConvolutionData(shape=(3,3),features=128,activation='elu'),data.BatchNormalizationData(),\n",
    "        data.ConvolutionData(shape=(3,3),features=128,activation='elu'),data.BatchNormalizationData(),\n",
    "        data.MaxPoolingData(shape=(2,2)), data.DropoutData(rate=0.5),\n",
    "        data.FlattenData(),\n",
    "        data.DenseData(units=128, activation='elu'),\n",
    "        data.BatchNormalizationData(),\n",
    "        data.DropoutData(rate=0.6),\n",
    "        data.DenseData(units=7, activation='softmax'),\n",
    "    ]\n",
    "\n",
    "    # dcnn_datas = [ #reference\n",
    "    #     data.ConvolutionData(shape=(5,5),features=64,activation='elu'),data.BatchNormalizationData(),\n",
    "    #     data.ConvolutionData(shape=(5,5),features=64,activation='elu'),data.BatchNormalizationData(),\n",
    "    #     data.MaxPoolingData(shape=(2,2)), data.DropoutData(rate=0.4),\n",
    "    #     data.ConvolutionData(shape=(3,3),features=128,activation='elu'),data.BatchNormalizationData(),\n",
    "    #     data.ConvolutionData(shape=(3,3),features=128,activation='elu'),data.BatchNormalizationData(),\n",
    "    #     data.MaxPoolingData(shape=(2,2)), data.DropoutData(rate=0.4),\n",
    "    #     data.ConvolutionData(shape=(3,3),features=256,activation='elu'),data.BatchNormalizationData(),\n",
    "    #     data.ConvolutionData(shape=(3,3),features=256,activation='elu'),data.BatchNormalizationData(),\n",
    "    #     data.MaxPoolingData(shape=(2,2)), data.DropoutData(rate=0.5),\n",
    "    #     data.FlattenData(),\n",
    "    #     data.DenseData(units=128, activation='elu'),\n",
    "    #     data.BatchNormalizationData(),\n",
    "    #     data.DropoutData(rate=0.6),\n",
    "    #     data.DenseData(units=7, activation='softmax'),\n",
    "    # ]\n",
    "    train_inputs_as_array, train_labels_as_one_hot_encoded = keras_inputs_and_labels_from_data_frame(sampled_train_data_frame)\n",
    "    validate_inputs_as_array, validate_labels_as_one_hot_encoded = keras_inputs_and_labels_from_data_frame(validate_data_frame)\n",
    "    return evolve_datas(\n",
    "        train_inputs_as_array=train_inputs_as_array,\n",
    "        train_labels_as_one_hot_encoded=train_labels_as_one_hot_encoded,\n",
    "        validate_inputs_as_array=validate_inputs_as_array,\n",
    "        validate_labels_as_one_hot_encoded=validate_labels_as_one_hot_encoded,\n",
    "        initial_dcnn_datas=dcnn_datas,\n",
    "        augmentation_datas=augmentation_datas,\n",
    "        preprocessing_datas=preprocessing_datas,\n",
    "        # retained_validation_accuracies=retained_validation_accuracies,\n",
    "    )\n",
    "saved_datas_path = test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540a5a79-95e8-485b-b46d-4706b8cde66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def load_datas_as_pickle(the_datas, destination_file_path):\n",
    "    with open(destination_file_path, 'rb') as handle:\n",
    "        loaded_datas = pickle.load(handle)\n",
    "        try_to_make_data_graph_from_loaded_data = path_data_graph_from_data_nodes( loaded_datas )\n",
    "        return loaded_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb75edb-6633-4aa4-8478-79d30bb01f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cehck we saved anything\n",
    "load_datas_as_pickle(saved_datas_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4fda3f-671d-4e52-9fec-a77a38c724f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d444147-90f5-4b05-bfa3-e91e252d1b8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24bf01c8-89ab-41f1-a5c4-27aeecc483ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def evolve_dcnn(\n",
    "#     train_image_series,\n",
    "#     train_labels_as_one_hot_encoded,\n",
    "#     validate_image_series,\n",
    "#     validate_labels_as_one_hot_encoded,\n",
    "#     initial_dcnn_datas,\n",
    "#     augmentation_datas,\n",
    "#     preprocessing_datas,\n",
    "#     # retained_dcnn_datas=[],\n",
    "#     # retained_validation_accuracies=[],\n",
    "# ):\n",
    "#     retained_dcnn_datas = initial_dcnn_datas\n",
    "\n",
    "#     def validation_accuracy_from_dcnn_datas(dcnn_datas):\n",
    "#         pipeline_path_data_graph = path_data_graph_from_data_nodes( augmentation_datas + preprocessing_datas + dcnn_datas )\n",
    "#         return scores_from_path_data_graph(\n",
    "#             last_data_node=pipeline_path_data_graph[-1],\n",
    "#             input_shape=(48,48),\n",
    "#             first_data_node=pipeline_path_data_graph[0],\n",
    "#             train_inputs=get_all_inputs_as_array_from_matrix_series(train_image_series),\n",
    "#             train_labels=keras.utils.to_categorical(train_labels_as_one_hot_encoded),\n",
    "#             validate_inputs=get_all_inputs_as_array_from_matrix_series(validate_image_series),\n",
    "#             validate_labels=keras.utils.to_categorical(validate_labels_as_one_hot_encoded),\n",
    "#             epochs=40,\n",
    "#             callbacks=[\n",
    "#                 keras.callbacks.EarlyStopping(patience=3, restore_best_weights=False, monitor='accuracy', min_delta=0.005, verbose=1),\n",
    "#                 keras.callbacks.EarlyStopping(patience=4, restore_best_weights=False, monitor='val_accuracy', min_delta=0.005, verbose=1),\n",
    "#                 TimeOut(t0=time.time(), timeout=2),\n",
    "#             ],\n",
    "#             verbose=1,\n",
    "#             batch_size=32,\n",
    "#         )['val_accuracy']\n",
    "        \n",
    "#     validation_accuracy = validation_accuracy_from_dcnn_datas(dcnn_datas=initial_dcnn_datas)    \n",
    "#     # validation_accuracy = 0.1    \n",
    "#     # while True:\n",
    "#     saved_datas_file_path = None\n",
    "#     for _ in range(10):\n",
    "#         print(\"try one mutation step\")\n",
    "#         try:\n",
    "#             new_dcnn_datas = mutated_dcnn_datas(retained_dcnn_datas)\n",
    "#             # print(f\"\\t{new_dcnn_datas = }\")\n",
    "#             new_validation_accuracy = validation_accuracy_from_dcnn_datas(new_dcnn_datas)\n",
    "#             if new_validation_accuracy > validation_accuracy:\n",
    "#                 print(f\"\\n new best val accuracy:{new_validation_accuracy = }\")\n",
    "#                 print(f\"new best model:{new_dcnn_datas}\")\n",
    "#                 yield \n",
    "#                 # retained_dcnn_datas.append(new_dcnn_datas)\n",
    "#                 # retained_validation_accuracies.append(new_validation_accuracy)\n",
    "#                 saved_datas_file_path = f\"{constant.architecture_folder_path}dcnn_validatation_accuracy_{int(validation_accuracy*100)}\"\n",
    "#                 save_datas_as_pickle(\n",
    "#                     new_dcnn_datas, \n",
    "#                     constant.data_folder_path, \n",
    "#                     saved_datas_file_path,\n",
    "#                 )\n",
    "#                 retained_dcnn_datas = new_dcnn_datas\n",
    "#                 validation_accuracy = new_validation_accuracy\n",
    "#             else:\n",
    "#                 print(\"no better model\")\n",
    "#         except Exception as e:\n",
    "#             print(f\"failed during mutation: {e}\")\n",
    "#             print(f\"{new_dcnn_datas = }\")\n",
    "#             raise(e)\n",
    "#         print(\"try one augmenting step\")\n",
    "#         try:\n",
    "#             new_dcnn_datas = expanded_dcnn_datas(retained_dcnn_datas)\n",
    "#             # print(f\"\\t{new_dcnn_datas = }\")\n",
    "#             new_validation_accuracy = validation_accuracy_from_dcnn_datas(new_dcnn_datas)\n",
    "#             if new_validation_accuracy > validation_accuracy:\n",
    "#                 print(f\"\\n new best val accuracy:{new_validation_accuracy = }\")\n",
    "#                 print(f\"new best model:{new_dcnn_datas}\")\n",
    "#                 # retained_dcnn_datas.append(new_dcnn_datas)\n",
    "#                 # retained_validation_accuracies.append(new_validation_accuracy)\n",
    "#                 saved_datas_file_path = f\"{constant.architecture_folder_path}dcnn_validatation_accuracy_{int(validation_accuracy*100)}\"\n",
    "#                 save_datas_as_pickle(\n",
    "#                     new_dcnn_datas, \n",
    "#                     constant.data_folder_path, \n",
    "#                     saved_datas_file_path,\n",
    "#                 )\n",
    "#                 retained_dcnn_datas = new_dcnn_datas\n",
    "#                 validation_accuracy = new_validation_accuracy\n",
    "#             else:\n",
    "#                 print(\"no better model\")\n",
    "#         except Exception as e:\n",
    "#             print(f\"failed during mutation: {e}\")\n",
    "#             print(f\"{new_dcnn_datas = }\")\n",
    "#             raise(e)\n",
    "#         print(\"try one reducing step\")\n",
    "#         try:\n",
    "#             new_dcnn_datas = shrank_dcnn_datas(retained_dcnn_datas)\n",
    "#             # print(f\"\\t{new_dcnn_datas = }\")\n",
    "#             new_validation_accuracy = validation_accuracy_from_dcnn_datas(new_dcnn_datas)\n",
    "#             if new_validation_accuracy > validation_accuracy:\n",
    "#                 print(f\"\\n new beretained_dcnn_datasst val accuracy:{new_validation_accuracy = }\")\n",
    "#                 print(f\"new best model:{new_dcnn_datas}\")\n",
    "#                 # retained_dcnn_datas.append(new_dcnn_datas)\n",
    "#                 # retained_validation_accuracies.append(new_validation_accuracy)\n",
    "#                 saved_datas_file_path = f\"{constant.architecture_folder_path}dcnn_validatation_accuracy_{int(validation_accuracy*100)}\"\n",
    "#                 save_datas_as_pickle(\n",
    "#                     new_dcnn_datas, \n",
    "#                     constant.data_folder_path, \n",
    "#                     saved_datas_file_path,\n",
    "#                 )\n",
    "#                 retained_dcnn_datas = new_dcnn_datas\n",
    "#                 validation_accuracy = new_validation_accuracy\n",
    "#             else:\n",
    "#                 print(\"no better model\")\n",
    "#         except Exception as e:\n",
    "#             print(f\"failed during mutation: {e}\")\n",
    "#             print(f\"{new_dcnn_datas = }\")\n",
    "#             # raise(e)\n",
    "\n",
    "#     return saved_datas_file_path"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emotion_from_face",
   "language": "python",
   "name": "emotion_from_face"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
