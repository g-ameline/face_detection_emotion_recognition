{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3b7e01e-e549-486d-9122-c568a4a66738",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02de903f-a0ee-40c0-89c4-55887c289154",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-28 17:00:43.952301: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-09-28 17:00:43.973575: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7809eff4-91da-4cc0-8b0c-dd091e415243",
   "metadata": {},
   "outputs": [],
   "source": [
    "import node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07ee0a91-c823-47c5-9d65-623a1dda5037",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbc70f8f-9b56-46c4-bce8-134be4994cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd149351-79d8-4b60-a00a-4b1fa5cf2fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec49eecb-36e4-4392-8abf-6acce45d411c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62db52ca-ffaf-4896-8be4-57aae5d3677a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os \n",
    "import constant\n",
    "\n",
    "def saved_file_path_from_object(the_object, destination_folder_path, file_name):\n",
    "    if not os.path.exists(destination_folder_path):\n",
    "        os.makedirs(destination_folder_path)\n",
    "    destination_file_path = f\"{destination_folder_path}{file_name}\"\n",
    "    with open(destination_file_path, 'wb') as handle:\n",
    "        pickle.dump(the_object, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    with open(destination_file_path, 'rb') as handle:\n",
    "        loaded_datas = pickle.load(handle)\n",
    "    return destination_file_path \n",
    "\n",
    "def object_from_file_path(destination_file_path):\n",
    "    with open(destination_file_path, 'rb') as handle:\n",
    "        loaded_object = pickle.load(handle)\n",
    "        return loaded_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6bf245e6-7de8-4f75-a2c4-0777335fd36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentation_datas = [\n",
    "    data.RandomRotationData(factor=0.005 ),\n",
    "    data.RandomTranslationData(height_factor=0.01, width_factor=0.01 ),\n",
    "    data.RandomFlipData(mode='horizontal' ),\n",
    "]\n",
    "\n",
    "preprocessing_datas = [\n",
    "    data.data_from_keras_layer( keras.layers.Reshape, target_shape=(48, 48, 1) ),\n",
    "]\n",
    "\n",
    "dcnn_datas = [ #reference\n",
    "        data.ConvolutionData(shape=(5,5),features=64,activation='elu'),data.BatchNormalizationData(),\n",
    "        data.ConvolutionData(shape=(5,5),features=64,activation='elu'),data.BatchNormalizationData(),\n",
    "        data.MaxPoolingData(shape=(2,2)), data.DropoutData(rate=0.4),\n",
    "        data.ConvolutionData(shape=(3,3),features=128,activation='elu'),data.BatchNormalizationData(),\n",
    "        data.ConvolutionData(shape=(3,3),features=128,activation='elu'),data.BatchNormalizationData(),\n",
    "        data.MaxPoolingData(shape=(2,2)), data.DropoutData(rate=0.4),\n",
    "        data.ConvolutionData(shape=(3,3),features=256,activation='elu'),data.BatchNormalizationData(),\n",
    "        data.ConvolutionData(shape=(3,3),features=256,activation='elu'),data.BatchNormalizationData(),\n",
    "        data.MaxPoolingData(shape=(2,2)), data.DropoutData(rate=0.5),\n",
    "        data.FlattenData(),\n",
    "        data.DenseData(units=128, activation='elu'),\n",
    "        data.BatchNormalizationData(),\n",
    "        data.DropoutData(rate=0.6),\n",
    "        data.DenseData(units=7, activation='softmax'),\n",
    "    ]\n",
    "reference_datas = augmentation_datas + preprocessing_datas +  dcnn_datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "278696b7-1162-45c1-bf71-6cd03669d52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickled_file_path = utils.pickled_file_path_from_object(\n",
    "    the_object=reference_datas, \n",
    "    destination_folder_path=constant.architecture_folder_path, \n",
    "    file_name=constant.architecture_file_name ,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "407c7a07-9f87-4229-b4eb-7f0c83b01ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../architecture/\n",
      "  â”” architecture\n"
     ]
    }
   ],
   "source": [
    "utils.show_folders_and_files('../architecture')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f70f0b3-5b7a-4e41-a14d-22a8b2f888ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[rotation data of factor 0.005,\n",
       " translation data of factor 0.01 & 0.01,\n",
       " flipdata of mode horizontal,\n",
       " reshape data of target_shape (48, 48, 1),\n",
       " convolution data of (5, 5) kernel with 64 features,\n",
       " batch normalization data,\n",
       " convolution data of (5, 5) kernel with 64 features,\n",
       " batch normalization data,\n",
       " max pooling data (2, 2),\n",
       " max pooling data 0.4,\n",
       " convolution data of (3, 3) kernel with 128 features,\n",
       " batch normalization data,\n",
       " convolution data of (3, 3) kernel with 128 features,\n",
       " batch normalization data,\n",
       " max pooling data (2, 2),\n",
       " max pooling data 0.4,\n",
       " convolution data of (3, 3) kernel with 256 features,\n",
       " batch normalization data,\n",
       " convolution data of (3, 3) kernel with 256 features,\n",
       " batch normalization data,\n",
       " max pooling data (2, 2),\n",
       " max pooling data 0.5,\n",
       " flatten data,\n",
       " dense data of 128 units,\n",
       " batch normalization data,\n",
       " max pooling data 0.6,\n",
       " dense data of 7 units]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.object_from_pickle_file_path(pickled_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6187971a-d6ec-4222-b6ba-df492c4c60e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emotion_from_face",
   "language": "python",
   "name": "emotion_from_face"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
