{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c888491-0583-4c68-83cd-ec85572f005d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e593e32-1dcf-41c1-82e6-89fd28959863",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69c40ef6-cb93-4b2c-ae42-1d2b65114872",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e8aea6b-ea42-4b0a-9e2e-a60592e5db0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# yunet_blob_url = 'https://github.com/opencv/opencv_zoo/raw/refs/heads/main/models/face_detection_yunet/face_detection_yunet_2023mar_int8.onnx'\n",
    "yunet_blob_url = 'https://github.com/opencv/opencv_zoo/raw/refs/heads/main/models/face_detection_yunet/face_detection_yunet_2023mar.onnx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b157f97-1194-49d3-96e7-c08c77f6b965",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_folder_path = '../model/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d07264eb-ac68-4de2-9adc-5c93dc819403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# yunet_file_name='yunet_int8.onnx'\n",
    "yunet_file_name='yunet.onnx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b9d3ddf-1c68-4343-8f84-6a0d3c29ada2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../model/\n",
      "  ├ dummy\n",
      "  ├ yunet.onnx\n",
      "  └ faces_and_rectangles_from_image\n"
     ]
    }
   ],
   "source": [
    "utils.show_folders_and_files(model_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0fb7f92-166c-48fc-ae4d-e618b45f1253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../model/\n",
      "  ├ dummy\n",
      "  ├ yunet.onnx\n",
      "  └ faces_and_rectangles_from_image\n"
     ]
    }
   ],
   "source": [
    "yunet_model_file_path = utils.fetch_file_stream(\n",
    "    url=yunet_blob_url, \n",
    "    destination_folder_path=model_folder_path, \n",
    "    data_file_name=yunet_file_name,\n",
    "    redownload=False,\n",
    ")\n",
    "utils.show_folders_and_files(model_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5bb51025-6142-435b-87d5-85dc136c3d13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../model/yunet.onnx'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yunet_model_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f676783c-4886-4f09-b9d6-65a7b409c7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yunet_face_extractor_function_from_saving_model_file_path(model_file_path, image_shape=(640,480)): #.onnx ?\n",
    "    face_extractor_model = cv2.FaceDetectorYN_create(model_file_path, \"\", (0, 0))\n",
    "    face_extractor_model.setInputSize(image_shape)\n",
    "    def faces_and_rectangles_from_image(image_array):\n",
    "        # assert image_array.shape, f\"image must have a shape -> numpy matrix : {image_array = } {type(image_array) = }\"        \n",
    "        _truc, faces = face_extractor_model.detect(image_array)\n",
    "        # print(f\"{faces = }\")\n",
    "        # print(f\"output of the face extractor {_truc = } {faces = }\")\n",
    "        \n",
    "        extracted_faces = []\n",
    "        rectangles = []\n",
    "        try:\n",
    "            if faces is not None:\n",
    "                for face in faces:\n",
    "                    x, y, w, h = list( int(v) for v in face[:4] )\n",
    "                    face_rectangle = image_array[y:y+h, x:x+w]\n",
    "                    face_gray = cv2.cvtColor(face_rectangle, cv2.COLOR_BGR2GRAY)\n",
    "                    face_resized = cv2.resize(face_gray, (48, 48))\n",
    "                    extracted_faces.append(face_resized)\n",
    "                    rectangles.append(top_left_and_bot_right:=((x, y), (x+w, y+h)))\n",
    "        except:\n",
    "            pass\n",
    "                \n",
    "        if faces is None:\n",
    "            pass\n",
    "        return extracted_faces, rectangles\n",
    "    \n",
    "    return faces_and_rectangles_from_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f608229-97f9-49cb-9c39-a4fbc65e2d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_device_index():\n",
    "    for device_index in range(0,200):\n",
    "        video_capture = cv2.VideoCapture(device_index)\n",
    "        if video_capture.isOpened():\n",
    "\n",
    "            ok, frame = video_capture.read()\n",
    "            if not ok:\n",
    "                continue\n",
    "            return device_index\n",
    "        if not video_capture.isOpened():\n",
    "            video_capture.release()\n",
    "            continue\n",
    "        # except:\n",
    "        #     print(f\"did not work {device_index = }\")\n",
    "        #     video_capture.release()\n",
    "    raise Exception(\"could not find a working webcam device, try : `!cameractrls -L` if you are on systemd linux distro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7b3c85b-862b-45d5-9790-e68700c706cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@0.433] global cap_v4l.cpp:999 open VIDEOIO(V4L2:/dev/video0): can't open camera by index\n",
      "[ WARN:0@0.437] global obsensor_stream_channel_v4l2.cpp:82 xioctl ioctl: fd=48, req=-2140645888\n",
      "[ WARN:0@0.437] global obsensor_stream_channel_v4l2.cpp:138 queryUvcDeviceInfoList ioctl error return: 25\n",
      "[ WARN:0@0.437] global obsensor_stream_channel_v4l2.cpp:82 xioctl ioctl: fd=48, req=-2140645888\n",
      "[ WARN:0@0.437] global obsensor_stream_channel_v4l2.cpp:138 queryUvcDeviceInfoList ioctl error return: 25\n",
      "[ WARN:0@0.437] global obsensor_stream_channel_v4l2.cpp:82 xioctl ioctl: fd=48, req=-2140645888\n",
      "[ WARN:0@0.437] global obsensor_stream_channel_v4l2.cpp:138 queryUvcDeviceInfoList ioctl error return: 25\n",
      "[ WARN:0@0.437] global obsensor_stream_channel_v4l2.cpp:82 xioctl ioctl: fd=48, req=-2140645888\n",
      "[ WARN:0@0.437] global obsensor_stream_channel_v4l2.cpp:138 queryUvcDeviceInfoList ioctl error return: 25\n",
      "[ WARN:0@0.437] global obsensor_stream_channel_v4l2.cpp:82 xioctl ioctl: fd=48, req=-2140645888\n",
      "[ WARN:0@0.437] global obsensor_stream_channel_v4l2.cpp:138 queryUvcDeviceInfoList ioctl error return: 25\n",
      "[ WARN:0@0.437] global obsensor_stream_channel_v4l2.cpp:82 xioctl ioctl: fd=48, req=-2140645888\n",
      "[ WARN:0@0.437] global obsensor_stream_channel_v4l2.cpp:138 queryUvcDeviceInfoList ioctl error return: 25\n",
      "[ WARN:0@0.437] global obsensor_stream_channel_v4l2.cpp:82 xioctl ioctl: fd=48, req=-2140645888\n",
      "[ WARN:0@0.437] global obsensor_stream_channel_v4l2.cpp:138 queryUvcDeviceInfoList ioctl error return: 25\n",
      "[ WARN:0@0.437] global obsensor_stream_channel_v4l2.cpp:82 xioctl ioctl: fd=48, req=-2140645888\n",
      "[ WARN:0@0.437] global obsensor_stream_channel_v4l2.cpp:138 queryUvcDeviceInfoList ioctl error return: 25\n",
      "[ WARN:0@0.437] global obsensor_stream_channel_v4l2.cpp:82 xioctl ioctl: fd=48, req=-2140645888\n",
      "[ WARN:0@0.437] global obsensor_stream_channel_v4l2.cpp:138 queryUvcDeviceInfoList ioctl error return: 25\n",
      "[ WARN:0@0.437] global obsensor_stream_channel_v4l2.cpp:82 xioctl ioctl: fd=48, req=-2140645888\n",
      "[ WARN:0@0.437] global obsensor_stream_channel_v4l2.cpp:138 queryUvcDeviceInfoList ioctl error return: 25\n",
      "[ERROR:0@0.554] global obsensor_uvc_stream_channel.cpp:158 getStreamChannelGroup Camera index out of range\n",
      "[ WARN:0@0.555] global cap_v4l.cpp:999 open VIDEOIO(V4L2:/dev/video1): can't open camera by index\n",
      "[ WARN:0@0.555] global obsensor_stream_channel_v4l2.cpp:82 xioctl ioctl: fd=48, req=-2140645888\n",
      "[ WARN:0@0.555] global obsensor_stream_channel_v4l2.cpp:138 queryUvcDeviceInfoList ioctl error return: 25\n",
      "[ WARN:0@0.555] global obsensor_stream_channel_v4l2.cpp:82 xioctl ioctl: fd=48, req=-2140645888\n",
      "[ WARN:0@0.555] global obsensor_stream_channel_v4l2.cpp:138 queryUvcDeviceInfoList ioctl error return: 25\n",
      "[ WARN:0@0.555] global obsensor_stream_channel_v4l2.cpp:82 xioctl ioctl: fd=48, req=-2140645888\n",
      "[ WARN:0@0.555] global obsensor_stream_channel_v4l2.cpp:138 queryUvcDeviceInfoList ioctl error return: 25\n",
      "[ WARN:0@0.555] global obsensor_stream_channel_v4l2.cpp:82 xioctl ioctl: fd=48, req=-2140645888\n",
      "[ WARN:0@0.555] global obsensor_stream_channel_v4l2.cpp:138 queryUvcDeviceInfoList ioctl error return: 25\n",
      "[ WARN:0@0.556] global obsensor_stream_channel_v4l2.cpp:82 xioctl ioctl: fd=48, req=-2140645888\n",
      "[ WARN:0@0.556] global obsensor_stream_channel_v4l2.cpp:138 queryUvcDeviceInfoList ioctl error return: 25\n",
      "[ WARN:0@0.556] global obsensor_stream_channel_v4l2.cpp:82 xioctl ioctl: fd=48, req=-2140645888\n",
      "[ WARN:0@0.556] global obsensor_stream_channel_v4l2.cpp:138 queryUvcDeviceInfoList ioctl error return: 25\n",
      "[ WARN:0@0.556] global obsensor_stream_channel_v4l2.cpp:82 xioctl ioctl: fd=48, req=-2140645888\n",
      "[ WARN:0@0.556] global obsensor_stream_channel_v4l2.cpp:138 queryUvcDeviceInfoList ioctl error return: 25\n",
      "[ WARN:0@0.556] global obsensor_stream_channel_v4l2.cpp:82 xioctl ioctl: fd=48, req=-2140645888\n",
      "[ WARN:0@0.556] global obsensor_stream_channel_v4l2.cpp:138 queryUvcDeviceInfoList ioctl error return: 25\n",
      "[ WARN:0@0.556] global obsensor_stream_channel_v4l2.cpp:82 xioctl ioctl: fd=48, req=-2140645888\n",
      "[ WARN:0@0.556] global obsensor_stream_channel_v4l2.cpp:138 queryUvcDeviceInfoList ioctl error return: 25\n",
      "[ WARN:0@0.556] global obsensor_stream_channel_v4l2.cpp:82 xioctl ioctl: fd=48, req=-2140645888\n",
      "[ WARN:0@0.556] global obsensor_stream_channel_v4l2.cpp:138 queryUvcDeviceInfoList ioctl error return: 25\n",
      "[ERROR:0@0.560] global obsensor_uvc_stream_channel.cpp:158 getStreamChannelGroup Camera index out of range\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_webcam_index = find_device_index()\n",
    "my_webcam_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb6b04c-6b27-4e8f-bfa9-949799a84167",
   "metadata": {},
   "source": [
    "# display webcam output but with frame around faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00ba12c6-4fc9-4c70-bec1-039c81bea7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def frame_faces_from_video(video_file_path_or_index, model_file_path ,create_face_extractor_from_model_path_and_image_shape ):\n",
    "    \n",
    "    # Open the video file\n",
    "    video_capture = cv2.VideoCapture(video_file_path_or_index)\n",
    "    webcam_shape = int(video_capture.get(cv2.CAP_PROP_FRAME_WIDTH)) , int(video_capture.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    faces_and_rectangles_from_image = yunet_face_extractor_function_from_saving_model_file_path(\n",
    "        model_file_path=model_file_path, \n",
    "        image_shape=webcam_shape,\n",
    "    )\n",
    "    if not video_capture.isOpened():\n",
    "        print(f\"Cannot open camera {video_capture = }\")\n",
    "        return\n",
    "    try:\n",
    "        while True:\n",
    "            ok, webcam_frame = video_capture.read()\n",
    "            if not ok:\n",
    "                print(f\"end of video stream {ok = }\")\n",
    "                break\n",
    "            faces, rectangles = faces_and_rectangles_from_image(webcam_frame)\n",
    "            if rectangles:\n",
    "                list(\n",
    "                    cv2.rectangle(webcam_frame, top_left, bottom_right, color=(255, 0, 0), thickness=2) \n",
    "                    for top_left, bottom_right in rectangles\n",
    "                )\n",
    "            cv2.imshow('webcam_frame', webcam_frame) # showing webcam output\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "    except Exception as error:\n",
    "        print(error)\n",
    "        pass    \n",
    "    video_capture.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f2d736ff-56ce-41e0-a21d-2c32cbe0f767",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'my_webcam_file_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m frame_faces_from_video(\n\u001b[0;32m----> 2\u001b[0m     video_file_path_or_index\u001b[38;5;241m=\u001b[39m\u001b[43mmy_webcam_file_path\u001b[49m, \n\u001b[1;32m      3\u001b[0m     model_file_path\u001b[38;5;241m=\u001b[39myunet_model_file_path, \n\u001b[1;32m      4\u001b[0m     create_face_extractor_from_model_path_and_image_shape\u001b[38;5;241m=\u001b[39myunet_face_extractor_function_from_saving_model_file_path,\n\u001b[1;32m      5\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'my_webcam_file_path' is not defined"
     ]
    }
   ],
   "source": [
    "frame_faces_from_video(\n",
    "    video_file_path_or_index=my_webcam_file_path, \n",
    "    model_file_path=yunet_model_file_path, \n",
    "    create_face_extractor_from_model_path_and_image_shape=yunet_face_extractor_function_from_saving_model_file_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8d1cdf-6d8b-4eb9-96d0-5685dfd09c05",
   "metadata": {},
   "source": [
    "# display only images of detected/extracted faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fddf5cce-2b27-4b9c-a77a-8cd0854c8fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def faces_from_video(video_file_path_or_index, model_file_path ,create_face_extractor_from_model_path_and_image_shape ):\n",
    "    \n",
    "    # Open the video file\n",
    "    video_capture = cv2.VideoCapture(video_file_path_or_index)\n",
    "    webcam_shape = int(video_capture.get(cv2.CAP_PROP_FRAME_WIDTH)) , int(video_capture.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    faces_and_rectangles_from_image = yunet_face_extractor_function_from_saving_model_file_path(\n",
    "        model_file_path=model_file_path, \n",
    "        image_shape=webcam_shape,\n",
    "    )\n",
    "    if not video_capture.isOpened():\n",
    "        print(f\"Cannot open camera {video_capture = }\")\n",
    "        return\n",
    "    try:\n",
    "        while True:\n",
    "            ok, webcam_frame = video_capture.read()\n",
    "            if not ok:\n",
    "                print(f\"end of video stream {ok = }\")\n",
    "                break\n",
    "            faces, rectangles = faces_and_rectangles_from_image(webcam_frame)\n",
    "            if faces and rectangles:\n",
    "                cv2.imshow('faces', numpy.hstack(faces))\n",
    "            else:\n",
    "                no_face_image = numpy.zeros((256,256))\n",
    "                no_face_image = cv2.putText(\n",
    "                    img=no_face_image,\n",
    "                    text='no face', \n",
    "                    org=(10,40),# bottomLeftCornerOfText, \n",
    "                    fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    fontScale=1,\n",
    "                    color=(255,255,255),\n",
    "                    thickness=4,\n",
    "                    bottomLeftOrigin=False,\n",
    "                )\n",
    "                cv2.imshow('faces', no_face_image)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "    except Exception as error:\n",
    "        print(error)\n",
    "        pass    \n",
    "    video_capture.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c5c1b29c-6120-4707-96b3-33c81bf2cd0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "qt.qpa.plugin: Could not find the Qt platform plugin \"wayland\" in \"\"\n"
     ]
    }
   ],
   "source": [
    "faces_from_video(\n",
    "    video_file_path_or_index=my_webcam_index, \n",
    "    model_file_path=yunet_model_file_path, \n",
    "    create_face_extractor_from_model_path_and_image_shape=yunet_face_extractor_function_from_saving_model_file_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a05cda7-bebe-41f5-9e94-4c229327db9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "faces_from_image",
   "language": "python",
   "name": "faces_from_image"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
